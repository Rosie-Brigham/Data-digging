{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I downloaded my classifications; now what?\n",
    "\n",
    "This notebook will help you take a first look at your data, to get basic information about it like: how many classifications, how many classifiers (signed in and not signed in), etc. It uses Python 2.7.\n",
    "\n",
    "There are scripts to do this, but first let's just get a sense of what the data looks like.\n",
    "\n",
    "Before we begin, though, we will need the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 2.7.11, numpy version: 1.11.0, pandas version: 0.19.2. \n",
      "Originally developed using Py 2.7.11, np v1.11.0, pd v0.19.2\n",
      "If these versions don't match and stuff breaks, that's probably why.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Python version: %d.%d.%d, numpy version: %s, pandas version: %s. \\nOriginally developed using Py 2.7.11, np v1.11.0, pd v0.19.2\" %(sys.version_info[0], sys.version_info[1], sys.version_info[2], np.__version__, pd.__version__))\n",
    "print(\"If these versions don't match and stuff breaks, that's probably why.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's say your project is called \"My Project\". We'll make that a variable below, because any of the files we need to access (classifications file, workflow contents file, etc) will start with that name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-project-classifications.csv\n"
     ]
    }
   ],
   "source": [
    "project_name = \"my-project\"\n",
    "\n",
    "classification_file = project_name + \"-classifications.csv\"\n",
    "\n",
    "print(classification_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in that file, using a package called `pandas` which is designed to handle large tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File my-project-classifications.csv read with 50000 rows.\n"
     ]
    }
   ],
   "source": [
    "classifications_all = pd.read_csv(classification_file)\n",
    "n_class = len(classifications_all)\n",
    "\n",
    "print(\"File %s read with %d rows.\" % (classification_file, n_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows, which we've saved as `n_class`, is the same as the total number of classifications recorded in this file. \n",
    "\n",
    "  **Note:** The more classifications in your file, the more memory it will take for your computer to work with them using `pandas`. From my experience, a few million rows isn't too big a deal as long as you have at least 8 GB of RAM. If you have a lot more, you may need something with more memory than a laptop, or you might want to use a script that doesn't try to hold them all in memory at once, or a package meant to be parallelized, like `dask`.\n",
    "\n",
    "What does each classification actually contain? Here are the column headers (*note: this example file may not have all the columns your actual data file will contain*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'classification_id', u'user_name', u'user_id', u'user_ip',\n",
       "       u'workflow_id', u'workflow_version', u'created_at', u'metadata',\n",
       "       u'subject_ids'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the file (i.e., each classification) includes:\n",
    "\n",
    " - **classification_id** - the unique ID assigned to each classification\n",
    " - **user_name** - the username the classifier chose when they registered on the site (this is public-facing as it's what they're identified with when they post on Talk)\n",
    " - **user_id** - the user's ID number in the Zooniverse database (this is not public; in the example file they've been hashed)\n",
    " - **user_ip** - a hashed version of the user's IP address\n",
    " - **workflow_id** - the ID number of the workflow this classification was recorded in\n",
    " - **workflow_name** - the text name of the workflow this classification was recorded in\n",
    " - **workflow_version** - the version number (format `major.minor`) of the workflow\n",
    " - **created_at** - the timestamp from when the classification was recorded\n",
    " - **metadata** - metadata from the classification such as browser information, operating system used\n",
    " - **annotations** - the actual information from the classification (answers / clicks / species identifications / etc, specific to this workflow id+version)\n",
    " - **subject_data** - the data on the subject that was uploaded as part of the subject upload\n",
    " - **subject_ids** - the unique identifier of all subjects classified in this classification (typically 1 subject)\n",
    " \n",
    "We can also quickly look at the first few rows in raw form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_ip</th>\n",
       "      <th>workflow_id</th>\n",
       "      <th>workflow_version</th>\n",
       "      <th>created_at</th>\n",
       "      <th>metadata</th>\n",
       "      <th>subject_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71432114</td>\n",
       "      <td>klmasters</td>\n",
       "      <td>9.762938e+09</td>\n",
       "      <td>152e3f84bcf873903f81</td>\n",
       "      <td>4958</td>\n",
       "      <td>17.6</td>\n",
       "      <td>2017-09-21 20:38:58 UTC</td>\n",
       "      <td>{\"session\":\"a72e45416496889a98c50417d2ad7e5aa8...</td>\n",
       "      <td>13093797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71432154</td>\n",
       "      <td>klmasters</td>\n",
       "      <td>9.762938e+09</td>\n",
       "      <td>152e3f84bcf873903f81</td>\n",
       "      <td>4958</td>\n",
       "      <td>17.6</td>\n",
       "      <td>2017-09-21 20:39:19 UTC</td>\n",
       "      <td>{\"session\":\"a72e45416496889a98c50417d2ad7e5aa8...</td>\n",
       "      <td>13094432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71432192</td>\n",
       "      <td>klmasters</td>\n",
       "      <td>9.762938e+09</td>\n",
       "      <td>152e3f84bcf873903f81</td>\n",
       "      <td>4958</td>\n",
       "      <td>17.6</td>\n",
       "      <td>2017-09-21 20:39:43 UTC</td>\n",
       "      <td>{\"session\":\"a72e45416496889a98c50417d2ad7e5aa8...</td>\n",
       "      <td>13094624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71432209</td>\n",
       "      <td>klmasters</td>\n",
       "      <td>9.762938e+09</td>\n",
       "      <td>152e3f84bcf873903f81</td>\n",
       "      <td>4958</td>\n",
       "      <td>17.6</td>\n",
       "      <td>2017-09-21 20:39:53 UTC</td>\n",
       "      <td>{\"session\":\"a72e45416496889a98c50417d2ad7e5aa8...</td>\n",
       "      <td>13094977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71432225</td>\n",
       "      <td>klmasters</td>\n",
       "      <td>9.762938e+09</td>\n",
       "      <td>152e3f84bcf873903f81</td>\n",
       "      <td>4958</td>\n",
       "      <td>17.6</td>\n",
       "      <td>2017-09-21 20:40:01 UTC</td>\n",
       "      <td>{\"session\":\"a72e45416496889a98c50417d2ad7e5aa8...</td>\n",
       "      <td>13098523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification_id  user_name       user_id               user_ip  \\\n",
       "0           71432114  klmasters  9.762938e+09  152e3f84bcf873903f81   \n",
       "1           71432154  klmasters  9.762938e+09  152e3f84bcf873903f81   \n",
       "2           71432192  klmasters  9.762938e+09  152e3f84bcf873903f81   \n",
       "3           71432209  klmasters  9.762938e+09  152e3f84bcf873903f81   \n",
       "4           71432225  klmasters  9.762938e+09  152e3f84bcf873903f81   \n",
       "\n",
       "   workflow_id  workflow_version               created_at  \\\n",
       "0         4958              17.6  2017-09-21 20:38:58 UTC   \n",
       "1         4958              17.6  2017-09-21 20:39:19 UTC   \n",
       "2         4958              17.6  2017-09-21 20:39:43 UTC   \n",
       "3         4958              17.6  2017-09-21 20:39:53 UTC   \n",
       "4         4958              17.6  2017-09-21 20:40:01 UTC   \n",
       "\n",
       "                                            metadata  subject_ids  \n",
       "0  {\"session\":\"a72e45416496889a98c50417d2ad7e5aa8...     13093797  \n",
       "1  {\"session\":\"a72e45416496889a98c50417d2ad7e5aa8...     13094432  \n",
       "2  {\"session\":\"a72e45416496889a98c50417d2ad7e5aa8...     13094624  \n",
       "3  {\"session\":\"a72e45416496889a98c50417d2ad7e5aa8...     13094977  \n",
       "4  {\"session\":\"a72e45416496889a98c50417d2ad7e5aa8...     13098523  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: user IDs have been changed for this example file and are not valid Zooniverse user IDs.*\n",
    "\n",
    "Even if you ignore the classification annotations themselves (which this example file is), there's still a lot of information in this classification file. Let's find out some other basic information about the classifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 classifications from 919 classifiers, of which 742 (81 percent) were signed-in and 177 (19 percent) were not signed in.\n",
      "\n",
      "Average classifications per user: 54.4\n"
     ]
    }
   ],
   "source": [
    "users_all = classifications_all['user_name'].unique()\n",
    "n_users = len(users_all)\n",
    "\n",
    "# if the classification is from a classifier who isn't signed in, the user_name field has \"not-logged-in-[user_ip]\"\n",
    "is_unreg = np.array([q.startswith(\"not-logged-in\") for q in users_all])\n",
    "is_reg   = np.invert(is_unreg)\n",
    "\n",
    "n_unreg = sum(is_unreg)\n",
    "n_reg   = sum(is_reg)\n",
    "\n",
    "print(\"%d classifications from %d classifiers, of which %d (%.0f percent) were signed-in and %d (%.0f percent) were not signed in.\\n\" % (n_class, n_users, n_reg, (float(n_reg)/float(n_users)*100.), n_unreg, (float(n_unreg)/float(n_users)*100.)))\n",
    "\n",
    "print(\"Average classifications per user: %.1f\" % (float(n_class)/float(n_users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifications registered between 2017-09-21 20:38:58 UTC and 2017-09-22 16:41:16 UTC.\n"
     ]
    }
   ],
   "source": [
    "# use created_at to print date range for classifications\n",
    "print(\"Classifications registered between %s and %s.\" % (classifications_all['created_at'][classifications_all.index[0]], classifications_all['created_at'][classifications_all.index[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest classification ID in this file: 71523948\n"
     ]
    }
   ],
   "source": [
    "# print out the classification ID of the last classification (useful in some cases)\n",
    "print(\"Latest classification ID in this file: %d\" % classifications_all['classification_id'][classifications_all.index[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's more we could do here: compute medians as well as averages, figure out the typical time it takes for a user to complete a classification, work out how many hours of human effort were spent classifying, etc. We could also clean the classification export of duplicate and non-live classifications, and isolate classifications from just the workflow ID + version that we want to actually analyze.\n",
    "\n",
    "However, that's for the next notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
